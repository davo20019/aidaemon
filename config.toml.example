# aidaemon configuration
#
# Secrets resolution order:
#   1. "keychain"    → reads from OS credential store (macOS Keychain, etc.)
#   2. "${ENV_VAR}"  → reads from environment variable (for Docker/CI)
#   3. "plain-value" → used as-is (not recommended for production)
#
# The setup wizard stores secrets in the OS keychain automatically.

[provider]
# Provider type: openai_compatible, google_genai, or anthropic
api_key = "keychain"
# api_key = "${AIDAEMON_API_KEY}"
base_url = "https://openrouter.ai/api/v1"

[provider.models]
primary = "openai/gpt-4o"
fast = "openai/gpt-4o-mini"
smart = "anthropic/claude-sonnet-4"

[telegram]
bot_token = "keychain"
# bot_token = "${TELOXIDE_TOKEN}"
allowed_user_ids = [123456789]

[state]
db_path = "aidaemon.db"
working_memory_cap = 50
# consolidation_interval_hours = 6  # How often to run memory consolidation (extract durable facts from conversations)
# encryption_key = "keychain"       # SQLCipher AES-256 encryption (requires: cargo build --features encryption)
# encryption_key = "${AIDAEMON_ENCRYPTION_KEY}"

[terminal]
# Set to ["*"] to allow all commands (only if you trust the LLM fully)
allowed_prefixes = ["ls", "cat", "head", "tail", "echo", "date", "whoami", "pwd", "find", "wc", "grep", "tree", "file", "stat", "uname", "df", "du", "ps", "which", "env", "printenv"]

[daemon]
health_port = 8080

# [skills]
# enabled = true
# dir = "skills"    # relative to config.toml location

# [browser]
# enabled = true
# headless = true
# screenshot_width = 1280
# screenshot_height = 720
# # Use an existing Chrome profile to inherit cookies/sessions (e.g. Cloudflare, GitHub, AWS)
# user_data_dir = "~/Library/Application Support/Google/Chrome"
# profile = "Default"    # or "Profile 1", "Profile 2", etc.

# [triggers.email]
# host = "imap.gmail.com"
# port = 993
# username = "you@gmail.com"
# password = "keychain"
# # password = "${AIDAEMON_EMAIL_PASSWORD}"
# folder = "INBOX"

# [search]
# backend = "brave"
# api_key = "keychain"
# # api_key = "${AIDAEMON_SEARCH_API_KEY}"

# [subagents]
# enabled = true
# max_depth = 3            # max nesting levels for sub-agents
# max_iterations = 10      # agentic loop iterations per sub-agent
# max_response_chars = 8000
# timeout_secs = 300       # 5 minute timeout per sub-agent

# [cli_agents]
# enabled = true
# timeout_secs = 600           # default timeout per invocation
# max_output_chars = 16000     # max output before truncation
#
# # Pre-configured tools (auto-discovered on startup via `which`)
# # Override or add your own:
# [cli_agents.tools.claude]
# command = "claude"
# args = ["-p", "--output-format", "json"]
#
# [cli_agents.tools.gemini]
# command = "gemini"
# args = ["-p", "--output-format", "json", "--sandbox=false"]
#
# [cli_agents.tools.codex]
# command = "codex"
# args = ["exec", "--json", "--full-auto"]

# [mcp.filesystem]
# command = "npx"
# args = ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]

# [policy]
# All policy features are enabled by default. Uncomment to override.
# policy_shadow_mode = true          # log old-vs-new routing comparisons
# policy_enforce = true              # use policy-based model routing
# tool_filter_enforce = true         # risk-based tool filtering
# uncertainty_clarify_enforce = true  # ask for clarification on ambiguous requests
# context_refresh_enforce = true      # mid-loop context budget refresh
# learning_evidence_gate_enforce = true  # stricter evidence thresholds for auto-learning
# autotune_shadow = true             # log auto-tune adjustments
# autotune_enforce = true            # apply auto-tune adjustments
# uncertainty_clarify_threshold = 0.55
# classify_retirement_enabled = true
# classify_retirement_window_days = 7
# classify_retirement_max_divergence = 0.05

[diagnostics]
enabled = true
record_decision_points = true
max_events = 200
include_raw_tool_args = false
