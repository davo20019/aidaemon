# aidaemon

A personal AI agent that runs as a background daemon, accessible via Telegram, with tool use, MCP integration, email triggers, and persistent memory.

I built this because I wanted to control my computer from my phone, from anywhere. I also wanted it to run on cheap hardware - a Raspberry Pi, an old laptop, a $5/month VPS - without eating all the RAM just to sit idle waiting for messages.

## Why Rust?

aidaemon runs 24/7 as a background daemon. It needs to be small, fast, and run on anything:

- **Runs on cheap/old hardware** - ~10 MB idle memory. A Node.js process sits at 50-80 MB doing nothing. On a Raspberry Pi or a $5 VPS with 512 MB RAM, that difference is the difference between running and not running.
- **Single binary, zero runtime** - `cargo install aidaemon` gives you one binary. No Node.js, no Python, no Docker. Copy it to any machine and run it.
- **Startup in milliseconds** - restarts after a crash are near-instant, which matters for the auto-recovery retry loop.
- **No garbage collector** - predictable latency. No GC pauses between receiving the LLM response and sending the Telegram message.

If you don't care about resource usage and want more features (WhatsApp, Slack, Discord, web UI), check out [OpenClaw](https://openclaw.ai) which does similar things in TypeScript.

## Features

- **Telegram interface** -chat with your AI assistant from any device
- **OpenAI-compatible provider** -works with OpenAI, OpenRouter, Ollama, Google AI Studio, or any compatible API
- **Agentic tool use** -the LLM can call tools (system info, terminal commands, MCP servers) in a loop
- **MCP client** -connect to any MCP server (filesystem, databases, etc.) and the agent gains those tools automatically
- **Persistent memory** -SQLite-backed conversation history + facts table, with fast in-memory working memory
- **Email triggers** -IMAP IDLE monitors your inbox and notifies you via Telegram on new emails
- **Health endpoint** -HTTP `/health` for monitoring
- **Service installer** -one command to install as a systemd or launchd service
- **Setup wizard** -interactive first-run setup, no manual config editing needed

## Quick Start

```bash
# Build
cargo build --release

# First run -launches the setup wizard
./target/release/aidaemon

# After setup, run the daemon
./target/release/aidaemon
```

The wizard will guide you through:
1. Selecting your LLM provider (OpenAI, OpenRouter, Ollama, Google AI Studio, etc.)
2. Entering your API key
3. Setting up your Telegram bot token and user ID

## Configuration

All settings live in `config.toml` (generated by the wizard). See [`config.toml.example`](config.toml.example) for the full reference.

### Provider

```toml
[provider]
api_key = "sk-..."
base_url = "https://openrouter.ai/api/v1"

[provider.models]
primary = "openai/gpt-4o"
fast = "openai/gpt-4o-mini"
smart = "anthropic/claude-sonnet-4"
```

### Telegram

```toml
[telegram]
bot_token = "123456:ABC-DEF..."
allowed_user_ids = [123456789]
```

### MCP Servers

```toml
[mcp.filesystem]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
```

### Email Triggers

```toml
[triggers.email]
host = "imap.gmail.com"
port = 993
username = "you@gmail.com"
password = "app-password"
folder = "INBOX"
```

### Terminal Tool

```toml
[terminal]
allowed_prefixes = ["ls", "cat", "echo", "date", "whoami"]
```

## Running as a Service

```bash
# macOS (launchd)
aidaemon install-service
launchctl load ~/Library/LaunchAgents/ai.aidaemon.plist

# Linux (systemd)
sudo aidaemon install-service
sudo systemctl enable --now aidaemon
```

## Inspired by OpenClaw

aidaemon was inspired by [OpenClaw](https://openclaw.ai) ([GitHub](https://github.com/openclaw/openclaw)), a personal AI assistant that runs on your own devices and connects to channels like WhatsApp, Telegram, Slack, Discord, Signal, iMessage, and more.

Both projects share the same goal: a self-hosted AI assistant you control. The key differences:

| | aidaemon | OpenClaw |
|---|---|---|
| **Language** | Rust | TypeScript/Node.js |
| **Channels** | Telegram (for now) | WhatsApp, Telegram, Slack, Discord, Signal, iMessage, Teams, and more |
| **Scope** | Minimal, single-binary daemon | Full-featured platform with web UI, canvas, TTS, browser control |
| **Config** | Single `config.toml` | JSON5 config with hot-reload and file watching |
| **Error recovery** | Inline error classification per HTTP status, model fallback, config backup rotation | Multi-layer retry policies, auth profile cooldowns, provider rotation, restart sentinels |
| **State** | SQLite + in-memory working memory (pluggable via trait) | Pluggable storage with session management |
| **Install** | `cargo install aidaemon` | npm/Docker |
| **Dependencies** | ~30 crates, single static binary | Node.js ecosystem |

aidaemon is designed for users who want a lightweight, single-purpose Telegram daemon in Rust. If you need multi-channel support, a web UI, or a richer plugin ecosystem, check out OpenClaw.

## Architecture

```
Telegram ──→ Agent ──→ LLM Provider (OpenAI-compatible)
               │
               ├──→ Tools (system info, terminal, MCP)
               ├──→ State (SQLite + in-memory working memory)
               └──→ Facts (Layer 2 memory, injected into system prompt)

Triggers (IMAP IDLE) ──→ EventBus ──→ Agent ──→ Telegram notification
Health server (axum) ──→ GET /health
```

- **Agent loop**: user message → build history → call LLM → if tool calls, execute and loop (max 10 iterations) → return final response
- **Working memory**: `VecDeque<Message>` in RAM, capped at N messages, hydrated from SQLite on cold start
- **Session ID** = Telegram chat ID
- **MCP**: spawns server subprocesses, communicates via JSON-RPC over stdio

## License

[MIT](LICENSE)
