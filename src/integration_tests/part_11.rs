// ==================== Context Window Management Tests ====================

/// Verify that a long conversation (20+ messages) doesn't crash and the agent
/// still produces a response. Budget enforcement should trim history silently.
#[tokio::test]
async fn test_long_conversation_no_crash() {
    // Create responses for 11 turns (22 messages total user+assistant)
    let mut responses = Vec::new();
    for i in 0..11 {
        responses.push(MockProvider::text_response(&format!("Response {}", i)));
    }

    let provider = MockProvider::with_responses(responses);
    let harness = setup_test_agent(provider).await.unwrap();

    // Send 11 messages in the same session
    for i in 0..11 {
        let msg = format!(
            "Message number {} with some extra text to make it a bit longer",
            i
        );
        let result = harness
            .agent
            .handle_message(
                "long_session",
                &msg,
                None,
                UserRole::Owner,
                ChannelContext::private("telegram"),
                None,
            )
            .await;

        assert!(
            result.is_ok(),
            "Message {} should succeed: {:?}",
            i,
            result.err()
        );
        let text = result.unwrap();
        assert!(!text.is_empty(), "Response {} should not be empty", i);
    }
}

/// Verify tool result compression: a very large tool result should be truncated.
#[tokio::test]
async fn test_tool_result_compressed() {
    use crate::memory::context_window::compress_tool_result;

    // Result under the limit should pass through unchanged
    let short = "Hello world";
    let result = compress_tool_result("terminal", short, 2000);
    assert_eq!(result, short);

    // Result over the limit should be truncated with annotation
    let large = "x".repeat(5000);
    let compressed = compress_tool_result("terminal", &large, 2000);
    assert!(compressed.len() < 5000);
    assert!(compressed.contains("[truncated"));
    assert!(compressed.contains("5000"));
}

/// Verify conversation summary CRUD operations work correctly.
#[tokio::test]
async fn test_summary_crud() {
    use crate::traits::ConversationSummary;

    let provider = MockProvider::with_responses(vec![MockProvider::text_response("Hello")]);
    let harness = setup_test_agent(provider).await.unwrap();

    // Initially no summary
    let summary = harness
        .state
        .get_conversation_summary("test_session")
        .await
        .unwrap();
    assert!(summary.is_none());

    // Upsert a summary
    let summary = ConversationSummary {
        session_id: "test_session".to_string(),
        summary: "We discussed topic A and decided on approach B.".to_string(),
        message_count: 10,
        last_message_id: "msg-123".to_string(),
        updated_at: Utc::now(),
    };
    harness
        .state
        .upsert_conversation_summary(&summary)
        .await
        .unwrap();

    // Retrieve it
    let loaded = harness
        .state
        .get_conversation_summary("test_session")
        .await
        .unwrap();
    assert!(loaded.is_some());
    let loaded = loaded.unwrap();
    assert_eq!(loaded.session_id, "test_session");
    assert_eq!(
        loaded.summary,
        "We discussed topic A and decided on approach B."
    );
    assert_eq!(loaded.message_count, 10);

    // Update it
    let updated = ConversationSummary {
        summary: "Updated: topic A, approach B, and new topic C.".to_string(),
        message_count: 15,
        ..loaded
    };
    harness
        .state
        .upsert_conversation_summary(&updated)
        .await
        .unwrap();

    let reloaded = harness
        .state
        .get_conversation_summary("test_session")
        .await
        .unwrap()
        .unwrap();
    assert_eq!(
        reloaded.summary,
        "Updated: topic A, approach B, and new topic C."
    );
    assert_eq!(reloaded.message_count, 15);

    // Clear session should also clear summary
    harness.state.clear_session("test_session").await.unwrap();
    let after_clear = harness
        .state
        .get_conversation_summary("test_session")
        .await
        .unwrap();
    assert!(
        after_clear.is_none(),
        "Summary should be deleted after clear_session"
    );
}

/// Verify should_extract_facts filters trivial messages correctly.
#[tokio::test]
async fn test_should_extract_facts_filtering() {
    use crate::memory::context_window::should_extract_facts;

    // Trivial messages should be filtered out
    assert!(!should_extract_facts("ok"));
    assert!(!should_extract_facts("thanks"));
    assert!(!should_extract_facts("ðŸ‘"));
    assert!(!should_extract_facts("hi")); // too short

    // Meaningful messages should pass through
    assert!(should_extract_facts(
        "My dog's name is Bella and she's 3 years old"
    ));
    assert!(should_extract_facts(
        "I work at Acme Corp as a senior engineer"
    ));
}

// â”€â”€â”€ Budget auto-extension integration tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/// Helper to collect StatusUpdate messages from a channel.
async fn collect_status_updates(
    mut rx: tokio::sync::mpsc::Receiver<StatusUpdate>,
) -> Vec<StatusUpdate> {
    let mut updates = Vec::new();
    while let Ok(update) = rx.try_recv() {
        updates.push(update);
    }
    updates
}

/// Task token budget auto-extends when the agent is making productive progress.
/// is_productive requires 8+ successful tool calls. We alternate between
/// system_info and remember_fact to avoid the repeated-call blocking guard
/// (which blocks non-exempt tools after 8 calls) while accumulating enough
/// successful calls to pass the is_productive threshold.
#[tokio::test]
async fn test_task_budget_auto_extends_on_progress() {
    let provider = MockProvider::with_responses(vec![
        // Alternate tools to avoid the 8-call same-tool block on system_info
        MockProvider::tool_call_response("system_info", "{}"),
        MockProvider::tool_call_response(
            "remember_fact",
            r#"{"category":"test","key":"k1","value":"v1"}"#,
        ),
        MockProvider::tool_call_response("system_info", r#"{"verbose": true}"#),
        MockProvider::tool_call_response(
            "remember_fact",
            r#"{"category":"test","key":"k2","value":"v2"}"#,
        ),
        MockProvider::tool_call_response("system_info", r#"{"check": "os"}"#),
        MockProvider::tool_call_response(
            "remember_fact",
            r#"{"category":"test","key":"k3","value":"v3"}"#,
        ),
        MockProvider::tool_call_response("system_info", r#"{"check": "mem"}"#),
        MockProvider::tool_call_response(
            "remember_fact",
            r#"{"category":"test","key":"k4","value":"v4"}"#,
        ),
        MockProvider::tool_call_response("system_info", r#"{"check": "cpu"}"#),
        MockProvider::tool_call_response(
            "remember_fact",
            r#"{"category":"test","key":"k5","value":"v5"}"#,
        ),
        // After budget extension (10 calls Ã— 15 = 150 tokens = budget hit):
        MockProvider::tool_call_response("system_info", r#"{"check": "final"}"#),
        // Final text response
        MockProvider::text_response("Task completed successfully."),
    ]);

    let mut harness = setup_test_agent(provider).await.unwrap();
    harness.agent.set_test_executor_mode();
    // Budget of 150 = 10 LLM calls at 15 tokens each. After 10 iterations,
    // total_successful_tool_calls >= 8 â†’ is_productive=true â†’ auto-extend.
    harness.agent.set_test_task_token_budget(Some(150));

    let (status_tx, status_rx) = tokio::sync::mpsc::channel::<StatusUpdate>(64);

    let response = harness
        .agent
        .handle_message(
            "budget_test",
            "Run a complex analysis requiring multiple steps",
            Some(status_tx),
            UserRole::Owner,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // The agent may either:
    // 1. Continue past the budget hit (old behavior: "Task completed successfully.")
    // 2. Gracefully stall after meaningful progress (new stopping_phase behavior)
    // 3. Return the last narration text when stopped by another mechanism
    // All are acceptable â€” the key is no crash and a non-empty response.
    assert!(
        !response.is_empty(),
        "Agent should return a non-empty response"
    );

    // BudgetExtended may or may not be emitted depending on whether the
    // stopping_phase's stall-with-progress path fires before the budget check.
    // We only verify if the agent completed successfully (reached final text).
    let updates = collect_status_updates(status_rx).await;
    if response.contains("Task completed successfully.") {
        let budget_extended = updates
            .iter()
            .any(|u| matches!(u, StatusUpdate::BudgetExtended { .. }));
        assert!(
            budget_extended,
            "Expected BudgetExtended status update when agent completes normally"
        );
    }
}

/// Task token budget stops execution when progress is not productive (stalling).
/// Script: same tool with same args â†’ stall detection â†’ is_productive=false â†’ stops.
#[tokio::test]
async fn test_task_budget_stops_when_not_productive() {
    // Create responses that will trigger stall detection.
    // 3 calls to hit the budget, but stall_count > 0 due to repetition.
    let mut responses = Vec::new();
    // Generate enough identical tool calls to trigger stall detection AND hit budget.
    // Stall detection fires at 3 consecutive identical calls (same name + same args hash).
    for _ in 0..5 {
        responses.push(MockProvider::tool_call_response("system_info", "{}"));
    }
    // Final text response (may not reach this if budget stops first)
    responses.push(MockProvider::text_response("Should not reach this."));

    let provider = MockProvider::with_responses(responses);
    let mut harness = setup_test_agent(provider).await.unwrap();
    harness.agent.set_test_executor_mode();
    harness.agent.set_test_task_token_budget(Some(45));

    let (status_tx, status_rx) = tokio::sync::mpsc::channel::<StatusUpdate>(64);

    let response = harness
        .agent
        .handle_message(
            "stall_test",
            "Do something",
            Some(status_tx),
            UserRole::Owner,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // Should have stopped â€” either by stall detection or budget exhaustion without extension
    // (stall_count > 0 makes is_productive=false)
    assert_ne!(response, "Should not reach this.");

    // Verify NO BudgetExtended was emitted
    let updates = collect_status_updates(status_rx).await;
    let budget_extended = updates
        .iter()
        .any(|u| matches!(u, StatusUpdate::BudgetExtended { .. }));
    assert!(
        !budget_extended,
        "BudgetExtended should NOT be emitted when agent is stalling"
    );
}

/// Goal daily budget auto-extends in-memory but is NOT persisted to the database.
/// With the tightened is_productive threshold (8+ successful calls), a low-call
/// scenario should stop at the budget without extending.
/// This test verifies the budget is NOT ratcheted up in the DB.
#[tokio::test]
async fn test_goal_budget_auto_extends_and_persists() {
    let provider = MockProvider::with_responses(vec![
        // Calls 1-4: tool calls (each adds 15 tokens to goal budget tracking)
        MockProvider::tool_call_response("system_info", "{}"),
        MockProvider::tool_call_response("system_info", r#"{"verbose": true}"#),
        MockProvider::tool_call_response("system_info", r#"{"check": "os"}"#),
        MockProvider::tool_call_response("system_info", r#"{"check": "mem"}"#),
        // Call 5: won't be reached â€” budget stops execution with only 3 successful calls
        MockProvider::text_response("Goal task completed."),
    ]);

    let mut harness = setup_test_agent(provider).await.unwrap();
    harness.agent.set_test_executor_mode();

    // Create a goal with a low daily budget (60 tokens = 4 LLM calls at 15 each)
    let mut goal = Goal::new_finite("Test goal for budget extension", "goal_budget_session");
    goal.status = "active".to_string();
    goal.budget_daily = Some(60);
    goal.budget_per_check = Some(500);
    harness.state.create_goal(&goal).await.unwrap();

    harness.agent.set_test_goal_id(Some(goal.id.clone()));

    let (status_tx, _status_rx) = tokio::sync::mpsc::channel::<StatusUpdate>(64);

    let response = harness
        .agent
        .handle_message(
            "goal_budget_session",
            "Execute the goal task",
            Some(status_tx),
            UserRole::Owner,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // With only 3 successful tool calls, is_productive returns false â†’ budget stops execution
    assert!(
        response.contains("daily token budget"),
        "Expected budget-exceeded message, got: {}",
        response
    );

    // Verify the budget was NOT persisted/inflated in the database
    let updated_goal = harness.state.get_goal(&goal.id).await.unwrap().unwrap();
    assert_eq!(
        updated_goal.budget_daily.unwrap(),
        60,
        "Budget should NOT be ratcheted up in DB â€” expected 60, got {:?}",
        updated_goal.budget_daily
    );
}

// â”€â”€â”€ Role-gate integration tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/// Non-owner (Guest) sending a schedule-like intent should not create a goal.
/// The request should be handled directly by the agent loop instead.
#[tokio::test]
async fn test_non_owner_cannot_schedule_goal() {
    let provider = MockProvider::with_responses(vec![
        // Consultant pass (iteration 0)
        MockProvider::text_response("I'll handle this request now."),
        // Agent loop (iteration 1) â€” after Scheduled intent is downgraded for Guest
        MockProvider::text_response("Here is the information you requested."),
    ]);

    let harness = setup_test_agent(provider).await.unwrap();

    let response = harness
        .agent
        .handle_message(
            "guest_schedule_session",
            "Every day at 9am, check the weather forecast",
            None,
            UserRole::Guest,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // Should get a response (not a scheduling confirmation)
    assert!(!response.is_empty());
    let call_log = harness.provider.call_log.lock().await;
    assert!(
        call_log.iter().all(|call| call.tools.is_empty()),
        "Guest schedule requests should be handled without tools"
    );

    // Verify no goals were created
    let goals = harness
        .state
        .get_pending_confirmation_goals("guest_schedule_session")
        .await
        .unwrap();
    assert!(
        goals.is_empty(),
        "Guest should not be able to create scheduled goals"
    );
}

/// Non-owner (Guest) saying "confirm" while Owner has pending goals should get
/// an owner-only message and the goal should remain pending.
#[tokio::test]
async fn test_non_owner_cannot_confirm_scheduled_goal() {
    let harness = setup_test_agent(MockProvider::new()).await.unwrap();

    // Create a pending_confirmation goal (as if Owner had initiated it)
    let mut goal = Goal::new_finite("Check weather daily", "confirm_test_session");
    goal.status = "pending_confirmation".to_string();
    harness.state.create_goal(&goal).await.unwrap();

    // Guest tries to confirm
    let response = harness
        .agent
        .handle_message(
            "confirm_test_session",
            "confirm",
            None,
            UserRole::Guest,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // Should get the owner-only message
    assert!(
        response.contains("Only the owner"),
        "Expected owner-only message, got: {}",
        response
    );

    // Goal should still be pending_confirmation (not activated or cancelled)
    let pending = harness
        .state
        .get_pending_confirmation_goals("confirm_test_session")
        .await
        .unwrap();
    assert_eq!(pending.len(), 1, "Goal should remain pending_confirmation");
    assert_eq!(pending[0].status, "pending_confirmation");
}

/// Regression: Non-owner sending an unrelated message should NOT auto-cancel
/// pending goals that belong to the Owner's session.
#[tokio::test]
async fn test_non_owner_unrelated_message_does_not_cancel_pending_goal() {
    let harness = setup_test_agent(MockProvider::new()).await.unwrap();

    // Create a pending_confirmation goal
    let mut goal = Goal::new_finite("Deploy app nightly", "shared_session");
    goal.status = "pending_confirmation".to_string();
    harness.state.create_goal(&goal).await.unwrap();

    // Guest sends unrelated message in the same session
    let _response = harness
        .agent
        .handle_message(
            "shared_session",
            "What's the weather today?",
            None,
            UserRole::Guest,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();

    // Goal should still be pending_confirmation â€” NOT cancelled
    let pending = harness
        .state
        .get_pending_confirmation_goals("shared_session")
        .await
        .unwrap();
    assert_eq!(
        pending.len(),
        1,
        "Pending goal should not be auto-cancelled by non-owner message"
    );
    assert_eq!(pending[0].status, "pending_confirmation");
}

fn test_reload_config(
    kind: &str,
    base_url: &str,
    api_key: &str,
    primary: &str,
    fast: &str,
    smart: &str,
) -> crate::config::AppConfig {
    let toml = format!(
        r#"
[provider]
kind = "{kind}"
base_url = "{base_url}"
api_key = "{api_key}"

[provider.models]
primary = "{primary}"
fast = "{fast}"
smart = "{smart}"
"#
    );
    toml::from_str(&toml).expect("reload test config should parse")
}

#[tokio::test]
async fn test_reload_provider_switches_backend_and_models_endpoint() {
    let harness = setup_test_agent(MockProvider::new()).await.unwrap();

    let before_models = harness.agent.list_models().await.unwrap();
    assert_eq!(before_models, vec!["mock-model".to_string()]);
    assert_eq!(harness.agent.current_model().await, "mock-model");

    let anthropic = test_reload_config(
        "anthropic",
        "https://api.openai.com/v1",
        "test-anthropic-key",
        "claude-3-haiku-20240307",
        "claude-3-haiku-20240307",
        "claude-3-opus-20240229",
    );

    let status = harness.agent.reload_provider(&anthropic).await.unwrap();
    assert!(
        status.contains("OpenaiCompatible -> Anthropic"),
        "unexpected reload status: {}",
        status
    );
    assert!(
        status.contains("mock-model -> claude-3-haiku-20240307"),
        "unexpected reload status: {}",
        status
    );
    assert_eq!(
        harness.agent.current_model().await,
        "claude-3-haiku-20240307"
    );

    let after_models = harness.agent.list_models().await.unwrap();
    assert!(
        after_models.iter().any(|m| m.starts_with("claude-3")),
        "expected Anthropic known models, got {:?}",
        after_models
    );
    assert!(
        !after_models.iter().any(|m| m == "mock-model"),
        "expected list_models source to switch away from mock provider, got {:?}",
        after_models
    );
}

#[tokio::test]
async fn test_reload_provider_resets_manual_model_and_supports_second_reload() {
    let harness = setup_test_agent(MockProvider::new()).await.unwrap();

    harness.agent.set_model("manual-override".to_string()).await;
    assert_eq!(harness.agent.current_model().await, "manual-override");

    let anthropic = test_reload_config(
        "anthropic",
        "https://api.openai.com/v1",
        "test-anthropic-key",
        "claude-3-opus-20240229",
        "claude-3-haiku-20240307",
        "claude-3-opus-20240229",
    );
    let status_1 = harness.agent.reload_provider(&anthropic).await.unwrap();
    assert!(
        status_1.contains("manual-override -> claude-3-opus-20240229"),
        "unexpected reload status: {}",
        status_1
    );
    assert_eq!(
        harness.agent.current_model().await,
        "claude-3-opus-20240229"
    );

    let openai = test_reload_config(
        "openai_compatible",
        "https://api.openai.com/v1",
        "test-openai-key",
        "openai/gpt-4o-mini",
        "openai/gpt-4o-mini",
        "openai/gpt-4o",
    );
    let status_2 = harness.agent.reload_provider(&openai).await.unwrap();
    assert!(
        status_2.contains("Anthropic -> OpenaiCompatible"),
        "unexpected second reload status: {}",
        status_2
    );
    assert!(
        status_2.contains("claude-3-opus-20240229 -> openai/gpt-4o-mini"),
        "unexpected second reload status: {}",
        status_2
    );
    assert_eq!(harness.agent.current_model().await, "openai/gpt-4o-mini");
}

#[tokio::test]
async fn test_no_router_auto_mode_uses_runtime_primary_over_stale_model_field() {
    let provider = MockProvider::with_responses(vec![MockProvider::text_response("ok")]);
    let mut harness = setup_test_agent(provider).await.unwrap();

    // Top-level orchestrator path (depth=0) with uniform models => no router.
    harness.agent.set_test_orchestrator_mode();

    // Create a stale local model field, then disable override.
    harness
        .agent
        .set_model("manual-stale-model".to_string())
        .await;
    harness.agent.clear_model_override().await;

    let response = harness
        .agent
        .handle_message(
            "no_router_auto_primary",
            "hello",
            None,
            UserRole::Owner,
            ChannelContext::private("test"),
            None,
        )
        .await
        .unwrap();
    assert!(
        !response.is_empty(),
        "agent should return a non-empty response"
    );

    let calls = harness.provider.call_log.lock().await;
    assert!(
        !calls.is_empty(),
        "expected at least one LLM call in orchestrator mode"
    );
    assert_eq!(
        calls[0].model, "mock-model",
        "top-level no-router auto mode should use runtime primary model, not stale self.model"
    );
}
